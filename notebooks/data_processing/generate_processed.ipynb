{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate processed data\n",
    "Here we will combine the subset of reviews with their labels and associated property description to create a processed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which GEO to process?\n",
    "GEO = \"florida\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the relevant data\n",
    "DATA_FP = \"../../data\"\n",
    "LABELS = pd.read_csv(DATA_FP + f\"/labels/{GEO}_reviews_labels.csv\")\n",
    "SUBSET = pd.read_csv(DATA_FP + f\"/filtered/{GEO}_reviews_filtered.csv\")\n",
    "LISTINGS = pd.read_csv(DATA_FP + f\"/raw/{GEO}_listings.csv\", encoding=\"unicode_escape\", low_memory=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we are dropping labels of \"maybe\". These are reviews we weren't sure about the label of. If we need more training data, we can revisit these reviews for labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of maybe/other reviews: 50/701\n"
     ]
    }
   ],
   "source": [
    "maybes_others = LABELS[(LABELS.label == \"maybe\") | (LABELS.label == \"other\")]\n",
    "print(f\"Number of maybe/other reviews: {len(maybes_others)}/{len(LABELS)}\")\n",
    "\n",
    "LABELS = LABELS[~((LABELS.label == \"maybe\") | (LABELS.label == \"other\"))]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join datasets together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join with labels\n",
    "subset_with_labels = pd.merge(LABELS, SUBSET, on=\"id\", suffixes=(\"_labels\", \"_subset\"))\n",
    "\n",
    "# join with listings\n",
    "subset_labels_and_listing = pd.merge(subset_with_labels, LISTINGS, left_on=\"listing_id\", right_on=\"id\", suffixes=(\"\",\"_listings\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only the columns we need for the processed dataset. Also, rename the columns to be more descriptive, and clean the amentities column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>description</th>\n",
       "      <th>comments</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>name</th>\n",
       "      <th>amenities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>142516857</td>\n",
       "      <td>6278267</td>\n",
       "      <td>Thank you looking at our Airbnb home - Villa G...</td>\n",
       "      <td>What an amazing place to stay! If you want to ...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>good</td>\n",
       "      <td>Hibiscus Hideaway</td>\n",
       "      <td>[TV, Cable TV, Internet, Wifi, Air conditionin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>201648190</td>\n",
       "      <td>6276494</td>\n",
       "      <td>Just steps away from the beach, The Delray at ...</td>\n",
       "      <td>This was our first Airbnb experience.  The apa...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>good</td>\n",
       "      <td>The Delray at Cabana Carioca</td>\n",
       "      <td>[TV, Cable TV, Internet, Wifi, Air conditionin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>73485649</td>\n",
       "      <td>2509161</td>\n",
       "      <td>NICE STUDIO IN HALLANDALE A FEW BLOCKS TO THE ...</td>\n",
       "      <td>The description is not entirely accurate - the...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>mgood</td>\n",
       "      <td>STUDIO APT 3 Blocks to BEACH w/POOL</td>\n",
       "      <td>[TV, Cable TV, Internet, Wifi, Air conditionin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>123961802</td>\n",
       "      <td>1127112</td>\n",
       "      <td>Hollywood Beach Resort is a beachfront histori...</td>\n",
       "      <td>Overall the place was as described . The bed w...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>good</td>\n",
       "      <td>Studio with kitchen at Beach Hotel</td>\n",
       "      <td>[TV, Internet, Wifi, Air conditioning, Pool, K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>445619904</td>\n",
       "      <td>1559542</td>\n",
       "      <td>Awesome space 1 mile south of downtown, 3 mile...</td>\n",
       "      <td>everything was quite good. I missed a dishwash...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>mgood</td>\n",
       "      <td>Private Home Near Downtown &amp; Beach remodeled!</td>\n",
       "      <td>[TV, Cable TV, Internet, Wifi, Air conditionin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     review_id  listing_id                                        description  \\\n",
       "608  142516857     6278267  Thank you looking at our Airbnb home - Villa G...   \n",
       "580  201648190     6276494  Just steps away from the beach, The Delray at ...   \n",
       "235   73485649     2509161  NICE STUDIO IN HALLANDALE A FEW BLOCKS TO THE ...   \n",
       "124  123961802     1127112  Hollywood Beach Resort is a beachfront histori...   \n",
       "643  445619904     1559542  Awesome space 1 mile south of downtown, 3 mile...   \n",
       "\n",
       "                                              comments  sentiment  label  \\\n",
       "608  What an amazing place to stay! If you want to ...        4.5   good   \n",
       "580  This was our first Airbnb experience.  The apa...        3.5   good   \n",
       "235  The description is not entirely accurate - the...        2.0  mgood   \n",
       "124  Overall the place was as described . The bed w...        4.0   good   \n",
       "643  everything was quite good. I missed a dishwash...        4.0  mgood   \n",
       "\n",
       "                                              name  \\\n",
       "608                              Hibiscus Hideaway   \n",
       "580                   The Delray at Cabana Carioca   \n",
       "235            STUDIO APT 3 Blocks to BEACH w/POOL   \n",
       "124             Studio with kitchen at Beach Hotel   \n",
       "643  Private Home Near Downtown & Beach remodeled!   \n",
       "\n",
       "                                             amenities  \n",
       "608  [TV, Cable TV, Internet, Wifi, Air conditionin...  \n",
       "580  [TV, Cable TV, Internet, Wifi, Air conditionin...  \n",
       "235  [TV, Cable TV, Internet, Wifi, Air conditionin...  \n",
       "124  [TV, Internet, Wifi, Air conditioning, Pool, K...  \n",
       "643  [TV, Cable TV, Internet, Wifi, Air conditionin...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_keep =[\n",
    "    \"id\",\n",
    "    \"listing_id\",\n",
    "    \"description\",\n",
    "    \"comments\",\n",
    "    \"sentiment\",\n",
    "    \"label\",\n",
    "    \"name\",\n",
    "    \"amenities\"\n",
    "]\n",
    "\n",
    "subset_labels_and_listing = subset_labels_and_listing[cols_to_keep]\n",
    "\n",
    "# rename id to review_id, for clarity\n",
    "subset_labels_and_listing = subset_labels_and_listing.rename(columns={\"id\": \"review_id\"})\n",
    "\n",
    "def parse_amenities(amenities):\n",
    "  amenities = amenities.replace(\"{\", \"\").replace(\"]\", \"\").replace('\"', \"\")\n",
    "  return amenities.split(\",\")\n",
    "\n",
    "subset_labels_and_listing.amenities = subset_labels_and_listing.amenities.apply(parse_amenities)\n",
    "\n",
    "subset_labels_and_listing.sample(n=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning text columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to clean the text columns to make them more useful for our model. We will do the following:\n",
    "\n",
    "- Convert to lowercase\n",
    "- remove some specific phrases that we know are not useful\n",
    "- Remove punctuation\n",
    "- Remove stop words\n",
    "- Lemmatize words\n",
    "\n",
    "We will use nltk to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\grego\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\grego\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing description...\n",
      "Preprocessing comments...\n",
      "Preprocessing name...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>description</th>\n",
       "      <th>comments</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>name</th>\n",
       "      <th>amenities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>51575200</td>\n",
       "      <td>5628197</td>\n",
       "      <td>[spacious, 1br, apartment, well, equipped, kit...</td>\n",
       "      <td>[matthew, not, left, instruction, get, key, he...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>good</td>\n",
       "      <td>[quiet, 1br, real, kitchen, central, ac]</td>\n",
       "      <td>[TV, Internet, Wifi, Air conditioning, Kitchen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>126283984</td>\n",
       "      <td>5628197</td>\n",
       "      <td>[spacious, 1br, apartment, well, equipped, kit...</td>\n",
       "      <td>[good, location, allergy, apartment, apartment...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>good</td>\n",
       "      <td>[quiet, 1br, real, kitchen, central, ac]</td>\n",
       "      <td>[TV, Internet, Wifi, Air conditioning, Kitchen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>188516052</td>\n",
       "      <td>4492175</td>\n",
       "      <td>[beautifully, decorated, room, wilton, manor, ...</td>\n",
       "      <td>[nice, place, stay, every, room, separate, ent...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>good</td>\n",
       "      <td>[red, room, heart, wilton, manor, heated, pool]</td>\n",
       "      <td>[TV, Cable TV, Wifi, Air conditioning, Pool, K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>416434132</td>\n",
       "      <td>5773722</td>\n",
       "      <td>[apartment, made, half, historical, 2, bedroom...</td>\n",
       "      <td>[nice, little, place, u, spend, night, heading...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>good</td>\n",
       "      <td>[sky, private, apartment, 2, pool, access]</td>\n",
       "      <td>[TV, Internet, Wifi, Air conditioning, Pool, K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>142486695</td>\n",
       "      <td>216046</td>\n",
       "      <td>[rest, assured, city, hollywood, state, florid...</td>\n",
       "      <td>[great, group, six, plenty, pool, table, large...</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>good</td>\n",
       "      <td>[ultimate, family, vacation]</td>\n",
       "      <td>[TV, Cable TV, Internet, Wifi, Air conditionin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     review_id  listing_id                                        description  \\\n",
       "523   51575200     5628197  [spacious, 1br, apartment, well, equipped, kit...   \n",
       "526  126283984     5628197  [spacious, 1br, apartment, well, equipped, kit...   \n",
       "379  188516052     4492175  [beautifully, decorated, room, wilton, manor, ...   \n",
       "543  416434132     5773722  [apartment, made, half, historical, 2, bedroom...   \n",
       "9    142486695      216046  [rest, assured, city, hollywood, state, florid...   \n",
       "\n",
       "                                              comments  sentiment label  \\\n",
       "523  [matthew, not, left, instruction, get, key, he...   4.000000  good   \n",
       "526  [good, location, allergy, apartment, apartment...   4.000000  good   \n",
       "379  [nice, place, stay, every, room, separate, ent...   4.000000  good   \n",
       "543  [nice, little, place, u, spend, night, heading...   4.000000  good   \n",
       "9    [great, group, six, plenty, pool, table, large...   4.666667  good   \n",
       "\n",
       "                                                name  \\\n",
       "523         [quiet, 1br, real, kitchen, central, ac]   \n",
       "526         [quiet, 1br, real, kitchen, central, ac]   \n",
       "379  [red, room, heart, wilton, manor, heated, pool]   \n",
       "543       [sky, private, apartment, 2, pool, access]   \n",
       "9                       [ultimate, family, vacation]   \n",
       "\n",
       "                                             amenities  \n",
       "523  [TV, Internet, Wifi, Air conditioning, Kitchen...  \n",
       "526  [TV, Internet, Wifi, Air conditioning, Kitchen...  \n",
       "379  [TV, Cable TV, Wifi, Air conditioning, Pool, K...  \n",
       "543  [TV, Internet, Wifi, Air conditioning, Pool, K...  \n",
       "9    [TV, Cable TV, Internet, Wifi, Air conditionin...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# download stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# remove negative words from stopwords\n",
    "negative_words = [\n",
    "    \"no\",\n",
    "    \"not\",\n",
    "    \"nor\",\n",
    "    \"neither\",\n",
    "    \"never\",\n",
    "    \"none\",\n",
    "    \"doesnt\",\n",
    "    \"couldnt\",\n",
    "    \"shouldnt\",\n",
    "    \"wouldnt\",\n",
    "    \"cant\",\n",
    "    \"cannot\",\n",
    "    \"wont\",\n",
    "    \"isnt\",\n",
    "    \"arent\",\n",
    "    \"wasnt\",\n",
    "    \"werent\",\n",
    "    \"hasnt\",\n",
    "    \"havent\",\n",
    "    \"hadnt\",\n",
    "    \"dont\",\n",
    "    \"didnt\",\n",
    "    \"neednt\",\n",
    "    \"very\"\n",
    "]\n",
    "for w in negative_words:\n",
    "    try:\n",
    "        stop_words.remove(w)\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "additional_stopwords = [\n",
    "    \"airbnb\",\n",
    "    \"austin\",\n",
    "    \"texas\",\n",
    "    \"home\",\n",
    "    \"house\"\n",
    "]\n",
    "for w in additional_stopwords:\n",
    "    stop_words.add(w)\n",
    "\n",
    "# remove some specific phrases, using regular expressions\n",
    "specific_phrases = [\n",
    "    r\"\\(.* hidden by airbnb\\)\",\n",
    "]\n",
    "\n",
    "\n",
    "# download lemmatizer\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def remove_stopwords_and_lemmatize(tokens) -> list:\n",
    "    processed_tokens = []\n",
    "    for w in tokens:\n",
    "        if w in stop_words:\n",
    "            continue\n",
    "        lemmatized = lemmatizer.lemmatize(w)\n",
    "        processed_tokens.append(lemmatized)\n",
    "\n",
    "    return processed_tokens\n",
    "\n",
    "def preprocess_text(text: str) -> list:\n",
    "    # lowercase\n",
    "    text: str = text.lower()\n",
    "\n",
    "    for phrase in specific_phrases:\n",
    "        text = re.sub(phrase, \"\", text)\n",
    "\n",
    "    # tokenize\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "\n",
    "    # remove stopwords and lemmatize\n",
    "    return remove_stopwords_and_lemmatize(tokens)\n",
    "\n",
    "print(\"Preprocessing description...\")\n",
    "subset_labels_and_listing.description = subset_labels_and_listing.description.apply(preprocess_text)\n",
    "\n",
    "print(\"Preprocessing comments...\")\n",
    "subset_labels_and_listing.comments = subset_labels_and_listing.comments.apply(preprocess_text)\n",
    "\n",
    "print(\"Preprocessing name...\")\n",
    "subset_labels_and_listing.name = subset_labels_and_listing.name.apply(preprocess_text)\n",
    "\n",
    "subset_labels_and_listing.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it\n",
    "subset_labels_and_listing.to_csv(DATA_FP + f\"/processed/{GEO}_processed.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf086def782804284d24881115c612afdcc8ea791299ba67855f0c7f1a9ccc5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
